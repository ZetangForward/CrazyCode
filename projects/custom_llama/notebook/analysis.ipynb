{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ËÆ°ÁÆóÂéãÁº©ÁéáÂèäÁªüËÆ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelZipper is ready for launchüöÄ | Current Versionü¶Ñ >>> 0.2.6 <<< | AOE Timeüïí 2024-01-05 15:37:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:01<00:00, 1668.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:01<00:00, 1270.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golden_svg_tokens:  811.4895\n",
      "p_predict_svg_tokens:  4608.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:44<00:00, 45.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:10<00:00, 183.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_str_tokens:  22720.927\n",
      "golden_str_tokens:  7261.193\n",
      "compress_codebook_tokens:  256\n",
      "ÂéãÁº©Áéá (codebook V.S. str): 28.36403515625 ÂÄç\n",
      "ÂéãÁº©Áéá (codebook V.S. numerical matrix): 3.169880859375 ÂÄç\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modelzipper.tutils import *\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "CodeLLaMA_PATH = \"/zecheng2/model_hub/CodeLlama-7b-hf\"\n",
    "FILE_PATH = \"/zecheng2/vqllama/test_vqllama_quantizer/test_1/visualized_compress_level_1/svg_paths.jsonl\"\n",
    "COMPRESSED_PATH = \"/zecheng2/vqllama/test_vqllama_quantizer/test_1/compress_level_1_predictions.pkl\"\n",
    "\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(CodeLLaMA_PATH)\n",
    "str_cotent = auto_read_data(FILE_PATH)\n",
    "compress_content = auto_read_data(COMPRESSED_PATH)\n",
    "\n",
    "# count compress svg tokens\n",
    "p_predict = compress_content['p_predict']\n",
    "golden = compress_content['golden']\n",
    "\n",
    "def count_non_pad_rows(x):\n",
    "    non_pad_rows = 0\n",
    "    for row in x:\n",
    "        row_list = row.tolist()\n",
    "        if row_list[0] == 0:\n",
    "            if any(row_list[1:]):\n",
    "                non_pad_rows += 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            non_pad_rows += 1\n",
    "    \n",
    "    return non_pad_rows\n",
    "\n",
    "\n",
    "def count_svg_tokens(batch_x):\n",
    "    \"\"\"\n",
    "    batch_x: [b, l, 9]\n",
    "    \"\"\"\n",
    "    total_tokens = 0\n",
    "    for i in trange(len(batch_x)):\n",
    "        item = batch_x[i]\n",
    "        non_pad_rows = count_non_pad_rows(item)\n",
    "        total_tokens += non_pad_rows * 9\n",
    "    avg_tokens = total_tokens / len(batch_x) \n",
    "    return avg_tokens\n",
    "\n",
    "golden_svg_tokens = count_svg_tokens(golden)\n",
    "p_predict_svg_tokens = count_svg_tokens(p_predict)\n",
    "\n",
    "print(\"golden_svg_tokens: \", golden_svg_tokens)\n",
    "print(\"p_predict_svg_tokens: \", p_predict_svg_tokens)\n",
    "\n",
    "\n",
    "def count_str_tokens(batch_x, tokenizer: AutoTokenizer):\n",
    "    \"\"\"\n",
    "    batch_x: List[str]\n",
    "    \"\"\"\n",
    "    total_tokens = 0\n",
    "    for i in trange(len(batch_x)):\n",
    "        item = batch_x[i]\n",
    "        tokens = tokenizer(item)['input_ids']\n",
    "        total_tokens += len(tokens)\n",
    "    avg_tokens = total_tokens / len(batch_x) \n",
    "    return avg_tokens\n",
    "\n",
    "\n",
    "p_svg_str = [item['p_svg_str'] for item in str_cotent]\n",
    "g_svg_str = [item['g_svg_str'] for item in str_cotent]\n",
    "\n",
    "p_svg_str_tokens = count_str_tokens(p_svg_str, llama_tokenizer)\n",
    "g_svg_str_tokens = count_str_tokens(g_svg_str, llama_tokenizer)\n",
    "\n",
    "print(\"p_str_tokens: \", p_svg_str_tokens)\n",
    "print(\"golden_str_tokens: \", g_svg_str_tokens)\n",
    "\n",
    "\n",
    "compress_codebook_tokens = compress_content['zs'].shape[-1]\n",
    "print(\"compress_codebook_tokens: \", compress_codebook_tokens)\n",
    "\n",
    "print(f\"ÂéãÁº©Áéá (codebook V.S. str): {g_svg_str_tokens / compress_codebook_tokens} ÂÄç\")\n",
    "print(f\"ÂéãÁº©Áéá (codebook V.S. numerical matrix): {golden_svg_tokens / compress_codebook_tokens} ÂÄç\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÊâìÂç∞ËæìÂá∫ÁªìÊûú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 4, 105]\n",
      "[1, 4, 105, 0, 0, 0, 0, 4, 200]\n",
      "[1, 4, 200, 0, 0, 0, 0, 199, 199]\n",
      "[1, 199, 199, 0, 0, 0, 0, 200, 4]\n",
      "[1, 200, 4, 0, 0, 0, 0, 5, 4]\n",
      "[1, 5, 4, 0, 0, 0, 0, 4, 101]\n",
      "[1, 4, 101, 0, 0, 0, 0, 1, 103]\n",
      "[0, 1, 103, 0, 0, 0, 0, 148, 89]\n",
      "[1, 148, 89, 0, 0, 0, 0, 152, 161]\n",
      "[1, 152, 161, 0, 0, 0, 0, 52, 170]\n"
     ]
    }
   ],
   "source": [
    "raw = compress_content.get('raw_predict')[0][: 10]\n",
    "golden = compress_content.get('golden')[0][: 10]\n",
    "p_predict = compress_content.get('p_predict')[0][: 10]\n",
    "\n",
    "\n",
    "def q_p(x):\n",
    "    for line in x:\n",
    "        print(line.tolist())\n",
    "\n",
    "\n",
    "q_p(p_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÊâæÂà∞ÂØπÂ∫îÁöÑSVG Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis not exist! --> Create data dir /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_36_raw_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_36_p_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_36_golden.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_66_raw_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_66_p_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_66_golden.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_72_raw_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_72_p_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_72_golden.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_80_raw_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_80_p_predict.txt | len: 1\n",
      "txt file saved successfully!\n",
      "Save file to /zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis/analysis_80_golden.txt | len: 1\n"
     ]
    }
   ],
   "source": [
    "from modelzipper.tutils import *\n",
    "from tqdm import trange\n",
    "\n",
    "ANALYSIS_DIR = \"/zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/analysis\"\n",
    "\n",
    "CodeLLaMA_PATH = \"/zecheng2/model_hub/CodeLlama-7b-hf\"\n",
    "FILE_PATH = \"/zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/visualized_compress_level_1/svg_paths.jsonl\"\n",
    "COMPRESSED_PATH = \"/zecheng2/vqllama/test_vqllama_quantizer/test_1/epoch_65/compress_level_1_predictions.pkl\"\n",
    "\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(CodeLLaMA_PATH)\n",
    "str_content = auto_read_data(FILE_PATH)\n",
    "compress_content = auto_read_data(COMPRESSED_PATH)\n",
    "\n",
    "raw_predict = compress_content['raw_predict']\n",
    "p_predict = compress_content['p_predict']\n",
    "golden = compress_content['golden']\n",
    "\n",
    "FILE_ID = [36, 66, 72, 80]\n",
    "\n",
    "\n",
    "def convert_tensor_to_str(x):\n",
    "    res = \"\"\n",
    "    for i in range(len(x)):\n",
    "        item = \"[\" + \",\".join([format(j, '5d') for j in x[i].tolist()]) + \"]\"\n",
    "        res += item + \"\\n\"\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "# TEMPLATE = \"raw predict:\\n{raw_predict}\\n\\np predict:\\n{p_predict}\\n\\ngolden:\\n{golden}\\n\\n\"\n",
    "\n",
    "for i in FILE_ID:\n",
    "    s_raw_predict = convert_tensor_to_str(raw_predict[i])\n",
    "    s_p_predict = convert_tensor_to_str(p_predict[i])\n",
    "    s_golden = convert_tensor_to_str(golden[i])\n",
    "    auto_save_data([s_raw_predict], os.path.join(ANALYSIS_DIR, f\"analysis_{i}_raw_predict.txt\"))\n",
    "    auto_save_data([s_p_predict], os.path.join(ANALYSIS_DIR, f\"analysis_{i}_p_predict.txt\"))\n",
    "    auto_save_data([s_golden], os.path.join(ANALYSIS_DIR, f\"analysis_{i}_golden.txt\"))\n",
    "    # s = TEMPLATE.format(raw_predict=s_raw_predict, p_predict=s_p_predict, golden=s_golden)\n",
    "    # auto_save_data([s], os.path.join(ANALYSIS_DIR, f\"analysis_{i}.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÁªüËÆ°Êï∞ÊçÆÈõÜÂπ≥ÂùáÈïøÂ∫¶ÔºåÊúÄÈïøÈïøÂ∫¶ÂíåÊúÄÁü≠ÈïøÂ∫¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 347000/347000 [00:00<00:00, 438812.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_length: 98.70044380403458\n",
      "max_length: 750\n",
      "min_length: 7\n",
      "Âå∫Èó¥ 0 Âà∞ 99 ÁöÑÊù°Êï∞: 228294\n",
      "Âå∫Èó¥ 100 Âà∞ 199 ÁöÑÊù°Êï∞: 92352\n",
      "Âå∫Èó¥ 200 Âà∞ 299 ÁöÑÊù°Êï∞: 17245\n",
      "Âå∫Èó¥ 300 Âà∞ 399 ÁöÑÊù°Êï∞: 5117\n",
      "Âå∫Èó¥ 400 Âà∞ 499 ÁöÑÊù°Êï∞: 2114\n",
      "Âå∫Èó¥ 500 Âà∞ 599 ÁöÑÊù°Êï∞: 1054\n",
      "Âå∫Èó¥ 600 Âà∞ 699 ÁöÑÊù°Êï∞: 608\n",
      "Âå∫Èó¥ 700 Âà∞ 799 ÁöÑÊù°Êï∞: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modelzipper.tutils import *\n",
    "from tqdm import trange\n",
    "\n",
    "FILE_PATH = \"/zecheng2/svg/icon-shop/mesh_data_svg_convert_p.pkl\"\n",
    "\n",
    "content = auto_read_data(FILE_PATH)\n",
    "\n",
    "\n",
    "total_length, max_length, min_length = 0, 0, 1000\n",
    "interval_counts = {}  # Êñ∞Â¢û‰∏Ä‰∏™Â≠óÂÖ∏Êù•Â≠òÂÇ®Âå∫Èó¥ËÆ°Êï∞\n",
    "\n",
    "for i in trange(len(content)):\n",
    "    svg_data = content[i]['mesh_data']\n",
    "    length = len(svg_data)\n",
    "    total_length += length\n",
    "    max_length = max(max_length, length)\n",
    "    min_length = min(min_length, length)\n",
    "    \n",
    "    # ËÆ°ÁÆóÂΩìÂâçÈïøÂ∫¶ÊâÄÂú®ÁöÑÂå∫Èó¥ÔºåÂπ∂Êõ¥Êñ∞ÂØπÂ∫îÂå∫Èó¥ÁöÑËÆ°Êï∞\n",
    "    interval = (length // 100) * 100\n",
    "    if interval not in interval_counts:\n",
    "        interval_counts[interval] = 0\n",
    "    interval_counts[interval] += 1\n",
    "\n",
    "avg_length = total_length / len(content)\n",
    "\n",
    "print(f\"avg_length: {avg_length}\")\n",
    "print(f\"max_length: {max_length}\")\n",
    "print(f\"min_length: {min_length}\")\n",
    "\n",
    "# ÊâìÂç∞Âá∫ÊØè‰∏™Âå∫Èó¥ÁöÑÊù°Êï∞\n",
    "for k in sorted(interval_counts):\n",
    "    print(f\"Âå∫Èó¥ {k} Âà∞ {k+99} ÁöÑÊù°Êï∞: {interval_counts[k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ê£ÄÊü•ÊµãËØïÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to read data from /zecheng2/svg/icon-shop/test_data_snaps/test_data_all_seq_with_mesh.pkl ...\n",
      "load config files from /workspace/zecheng/modelzipper/projects/custom_llama/configs/deepspeed/vqvae_config_v2.yaml\n",
      "config loaded successfully!\n",
      "config: namespace(ckpt_path='/zecheng2/vqllama/vqllama_quantizer/version_12/checkpoints/last.ckpt', vqvae=namespace(levels=2, downs_t=[1, 1], strides_t=[2, 2], emb_width=4096, l_bins=4096, l_mu=0.99, spectral=0.0, multispectral=1.0, hvqvae_multipliers=[2, 1, 1], loss_fn='l2', dilation_growth_rate=1, use_nonrelative_specloss=True, use_bottleneck=True, commit=1.0, recon=1.0, linf_k=2048, use_modified_block=False), vqvae_conv_block=namespace(depth=4, width=512, m_conv=1.0, dilation_growth_rate=1, dilation_cycle=None, vqvae_reverse_decoder_dilation=True), dataset=namespace(max_path_nums=512, min_path_nums=4, pad_token_id=0, train_batch_size=128, val_batch_size=32, nworkers=16, pin_memory=False, x_channels=9, inference_mode=False, vocab_size=200, return_all_token_mask=False, num_bins=9, remove_redundant_col=False))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1929/2000 [14:16<00:31,  2.25it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m vq_test \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m---> 67\u001b[0m     keys \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_input_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m     cur_save_case \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m\"\u001b[39m: keys}\n\u001b[1;32m     69\u001b[0m     zs \u001b[38;5;241m=\u001b[39m dataset[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg_tensors\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/workspace/zecheng/modelzipper/projects/custom_llama/data/vqseq2seq_dataset.py:209\u001b[0m, in \u001b[0;36mOfflineBasicDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    208\u001b[0m     mesh_data \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmesh_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmesh_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mequal(EDGE):\n\u001b[1;32m    210\u001b[0m         mesh_data \u001b[38;5;241m=\u001b[39m mesh_data[\u001b[38;5;241m7\u001b[39m:]\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: text_input_ids,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: text_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: mesh_data,\n\u001b[1;32m    218\u001b[0m     }\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import transformers\n",
    "import sys\n",
    "sys.path.append(\"/workspace/zecheng/modelzipper/projects/custom_llama\")\n",
    "from dataclasses import dataclass, field\n",
    "from transformers import Trainer\n",
    "from modelzipper.tutils import *\n",
    "from data.vqseq2seq_dataset import OfflineBasicDataset\n",
    "from models.vqvae import VQVAE, postprocess\n",
    "from data.svg_data import *\n",
    "import pytorch_lightning as pl\n",
    "from utils.visualize_svg import convert_svg\n",
    "import transformers\n",
    "from tqdm import trange\n",
    "from PIL import Image\n",
    "\n",
    "FILE_PATH = \"/zecheng2/svg/icon-shop/test_data_snaps/test_data_all_seq_with_mesh.pkl\"\n",
    "\n",
    "VQVAE_CONFIG_PATH = \"/workspace/zecheng/modelzipper/projects/custom_llama/configs/deepspeed/vqvae_config_v2.yaml\"\n",
    "DATA_PATH = \"/zecheng2/svg/icon-shop/test_data_snaps/test_data_all_seq_with_mesh.pkl\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"/zecheng2/model_hub/flan-t5-xl\")\n",
    "\n",
    "content = auto_read_data(DATA_PATH)\n",
    "dataset = OfflineBasicDataset(content=content, tokenizer=tokenizer, mode='test')\n",
    "vqvae_config = load_yaml_config(VQVAE_CONFIG_PATH)\n",
    "\n",
    "block_kwargs = dict(\n",
    "        width=vqvae_config.vqvae_conv_block.width, \n",
    "        depth=vqvae_config.vqvae_conv_block.depth, \n",
    "        m_conv=vqvae_config.vqvae_conv_block.m_conv,\n",
    "        dilation_growth_rate=vqvae_config.vqvae_conv_block.dilation_growth_rate,\n",
    "        dilation_cycle=vqvae_config.vqvae_conv_block.dilation_cycle,\n",
    "        reverse_decoder_dilation=vqvae_config.vqvae_conv_block.vqvae_reverse_decoder_dilation\n",
    "    )\n",
    "\n",
    "def add_background(image_obj=None, save_suffix=\"b\", raw_image_size_w=None, raw_image_size_h=None):\n",
    "    image = image_obj\n",
    "   \n",
    "    sub_image_w = raw_image_size_w if raw_image_size_w is not None else image.size[0]\n",
    "    sub_image_h = raw_image_size_h if raw_image_size_h is not None else image.size[1]\n",
    "\n",
    "    new_image_size = (sub_image_w, sub_image_h)\n",
    "    background_image = Image.new('RGB', new_image_size)\n",
    "\n",
    "    background_image.paste(image, (0, 0))\n",
    "\n",
    "    return background_image\n",
    "\n",
    "class PluginVQVAE(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "vqvae = VQVAE(vqvae_config, multipliers=None, **block_kwargs)\n",
    "plugin_vqvae = PluginVQVAE(vqvae)\n",
    "checkpoint = torch.load(vqvae_config.ckpt_path)  # load vqvae ckpt\n",
    "plugin_vqvae.load_state_dict(checkpoint['state_dict'])\n",
    "plugin_vqvae.eval()\n",
    "plugin_vqvae.cuda()\n",
    "plugin_vqvae.model.half()\n",
    "\n",
    "vq_test = []\n",
    "for i in trange(len(dataset)):\n",
    "    \n",
    "    try:\n",
    "        sample = dataset[i]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    keys = tokenizer.decode(dataset[i]['text_input_ids'], skip_special_tokens=True)\n",
    "    cur_save_case = {\"keys\": keys}\n",
    "    zs = dataset[i]['svg_tensors'][1:]\n",
    "    cur_save_case['zs_len'] = len(zs)\n",
    "    with torch.no_grad():\n",
    "        PI_RES = plugin_vqvae.model.decode(zs.unsqueeze(0).cuda(), 0, 1, padding_mask=None, path_interpolation=True, return_postprocess=True)[0]\n",
    "        PC_RES = plugin_vqvae.model.decode(zs.unsqueeze(0).cuda(), 0, 1, padding_mask=None, path_interpolation=False, return_postprocess=True)[0]\n",
    "        \n",
    "        cur_save_case['pi_res_len'] = PI_RES.size(0)\n",
    "        cur_save_case['pc_res_len'] = PC_RES.size(0)\n",
    "        cur_save_case['gt_res_len'] = dataset[i]['mesh_data'].size(0)\n",
    "        \n",
    "        PI_RES_image, PI_RES_str = convert_svg(PI_RES, True)\n",
    "        PC_RES_image, PC_RES_str = convert_svg(PC_RES, True)\n",
    "        GOLDEN_image, GT_str = convert_svg(dataset[i]['mesh_data'], True)\n",
    "        \n",
    "        cur_save_case['pi_res_str'] = PI_RES_image.numericalize(n=200).to_str()\n",
    "        cur_save_case['pc_res_str'] = PC_RES_image.numericalize(n=200).to_str()\n",
    "        cur_save_case['gt_str'] = GOLDEN_image.numericalize(n=200).to_str()\n",
    "        \n",
    "        PI_RES_IMAGE_PATH = os.path.join(\"/zecheng2/evaluation/test_vq/version_8/image\", f\"PI_{i}.png\")\n",
    "        PC_RES_IMAGE_PATH = os.path.join(\"/zecheng2/evaluation/test_vq/version_8/image\", f\"PC_{i}.png\")\n",
    "        GT_IMAGE_PATH = os.path.join(\"/zecheng2/evaluation/test_vq/version_8/image\", f\"GT_{i}.png\")\n",
    "        \n",
    "        # PI_RES_image_b = add_background(PI_RES_image)\n",
    "        # PC_RES_image_b = add_background(PC_RES_image)\n",
    "        # GT_RES_image_b = add_background(GT_IMAGE_PATH)\n",
    "        \n",
    "        PI_RES_image.save_png(PI_RES_IMAGE_PATH)\n",
    "        PC_RES_image.save_png(PC_RES_IMAGE_PATH)\n",
    "        GOLDEN_image.save_png(GT_IMAGE_PATH)\n",
    "        \n",
    "        cur_save_case['PI_RES_image_path'] = PI_RES_IMAGE_PATH\n",
    "        cur_save_case['PC_RES_image_path'] = PC_RES_IMAGE_PATH\n",
    "        cur_save_case['GT_image_path'] = GT_IMAGE_PATH\n",
    "        \n",
    "        vq_test.append(cur_save_case)\n",
    "    \n",
    "auto_save_data(vq_test, \"/zecheng2/evaluation/test_vq/version_8/vq_test.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([189, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI_RES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keys': ['Money', 'note', 'cash', 'bill', 'currency'],\n",
       " 'zs': tensor([  82, 4071, 1379, 2577, 1424, 1791, 2885, 1875, 1875, 1347, 3367, 3230,\n",
       "         1643, 1242, 2886, 1353, 2007, 2448,  602, 3053, 3472, 2881, 3036,  908,\n",
       "          294, 3165, 3494, 3230, 3367, 1337, 2271, 2994,  646, 1794, 1337, 2663,\n",
       "         4066, 2790, 2074, 1393, 4066, 2592, 2419,  666, 1439, 1448, 2441,  933,\n",
       "         3983, 1280,  892, 2812, 3272, 3644,  380,  713, 1527, 2812, 3272, 3644,\n",
       "          380,  436]),\n",
       " 'level': 'short',\n",
       " 'mesh_data': tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,  37.],\n",
       "         [  2.,   4.,  37.,   4.,  70.,   4.,  70.,   6.,  67.],\n",
       "         [  2.,   6.,  67.,   8.,  63.,  65.,   7.,  68.,   5.],\n",
       "         [  2.,  68.,   5.,  70.,   4.,  62.,   4.,  37.,   4.],\n",
       "         [  1.,  37.,   4.,   0.,   0.,   0.,   0.,   4.,   4.],\n",
       "         [  1.,   4.,   4.,   0.,   0.,   0.,   0.,   4.,  37.],\n",
       "         [  1.,   4.,  37.,   0.,   0.,   0.,   0.,   4.,  37.],\n",
       "         [  0.,   4.,  37.,   0.,   0.,   0.,   0., 109.,  36.],\n",
       "         [  2., 109.,  36., 127.,  54., 156.,  82., 173.,  99.],\n",
       "         [  1., 173.,  99.,   0.,   0.,   0.,   0., 199., 131.],\n",
       "         [  1., 199., 131.,   0.,   0.,   0.,   0., 199.,   4.],\n",
       "         [  1., 199.,   4.,   0.,   0.,   0.,   0.,  77.,   4.],\n",
       "         [  1.,  77.,   4.,   0.,   0.,   0.,   0., 109.,  36.],\n",
       "         [  1., 109.,  36.,   0.,   0.,   0.,   0., 109.,  36.],\n",
       "         [  0., 109.,  36.,   0.,   0.,   0.,   0.,  42.,  42.],\n",
       "         [  2.,  42.,  42.,  26.,  59.,  12.,  73.,  12.,  73.],\n",
       "         [  2.,  12.,  73.,  12.,  74.,  22.,  84.,  34.,  96.],\n",
       "         [  2.,  34.,  96.,  55., 117.,  56., 118.,  55., 114.],\n",
       "         [  2.,  55., 114.,  51.,  98.,  57.,  80.,  70.,  68.],\n",
       "         [  2.,  70.,  68.,  82.,  57.,  99.,  52., 114.,  55.],\n",
       "         [  2., 114.,  55., 118.,  56., 117.,  55.,  96.,  34.],\n",
       "         [  2.,  96.,  34.,  84.,  22.,  74.,  12.,  73.,  12.],\n",
       "         [  2.,  73.,  12.,  73.,  12.,  59.,  26.,  42.,  42.],\n",
       "         [  1.,  42.,  42.,   0.,   0.,   0.,   0.,  42.,  42.],\n",
       "         [  0.,  42.,  42.,   0.,   0.,   0.,   0.,  94.,  63.],\n",
       "         [  2.,  94.,  63.,  88.,  65.,  78.,  71.,  74.,  76.],\n",
       "         [  2.,  74.,  76.,  71.,  78.,  68.,  83.,  66.,  87.],\n",
       "         [  2.,  66.,  87.,  63.,  93.,  63.,  95.,  63., 104.],\n",
       "         [  2.,  63., 104.,  63., 113.,  63., 115.,  66., 121.],\n",
       "         [  2.,  66., 121.,  72., 134.,  83., 142.,  97., 145.],\n",
       "         [  2.,  97., 145., 125., 150., 150., 125., 145.,  97.],\n",
       "         [  2., 145.,  97., 140.,  73., 118.,  58.,  94.,  63.],\n",
       "         [  1.,  94.,  63.,   0.,   0.,   0.,   0.,  94.,  63.],\n",
       "         [  0.,  94.,  63.,   0.,   0.,   0.,   0.,   4., 141.],\n",
       "         [  1.,   4., 141.,   0.,   0.,   0.,   0.,   4., 199.],\n",
       "         [  1.,   4., 199.,   0.,   0.,   0.,   0., 131., 199.],\n",
       "         [  1., 131., 199.,   0.,   0.,   0.,   0.,  99., 173.],\n",
       "         [  2.,  99., 173.,  82., 156.,  54., 127.,  36., 109.],\n",
       "         [  1.,  36., 109.,   0.,   0.,   0.,   0.,   4.,  77.],\n",
       "         [  1.,   4.,  77.,   0.,   0.,   0.,   0.,   4., 141.],\n",
       "         [  1.,   4., 141.,   0.,   0.,   0.,   0.,   4., 141.],\n",
       "         [  0.,   4., 141.,   0.,   0.,   0.,   0., 153.,  94.],\n",
       "         [  2., 153.,  94., 157., 110., 151., 128., 138., 140.],\n",
       "         [  2., 138., 140., 126., 151., 109., 156.,  94., 153.],\n",
       "         [  2.,  94., 153.,  90., 152.,  91., 153., 112., 174.],\n",
       "         [  2., 112., 174., 124., 186., 134., 196., 135., 196.],\n",
       "         [  2., 135., 196., 136., 196., 196., 136., 196., 135.],\n",
       "         [  2., 196., 135., 196., 134., 186., 124., 174., 112.],\n",
       "         [  2., 174., 112., 153.,  91., 152.,  90., 153.,  94.],\n",
       "         [  1., 153.,  94.,   0.,   0.,   0.,   0., 153.,  94.],\n",
       "         [  0., 153.,  94.,   0.,   0.,   0.,   0., 199., 140.],\n",
       "         [  2., 199., 140., 199., 141., 148., 197., 142., 199.],\n",
       "         [  1., 142., 199.,   0.,   0.,   0.,   0., 138., 199.],\n",
       "         [  1., 138., 199.,   0.,   0.,   0.,   0., 199., 199.],\n",
       "         [  1., 199., 199.,   0.,   0.,   0.,   0., 199., 171.],\n",
       "         [  2., 199., 171., 199., 153., 199., 138., 199., 138.],\n",
       "         [  2., 199., 138., 199., 138., 199., 139., 199., 140.],\n",
       "         [  1., 199., 140.,   0.,   0.,   0.,   0., 199., 140.]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
