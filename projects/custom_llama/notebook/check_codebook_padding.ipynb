{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查给codebook引入Padding之后是否会影响模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import transformers\n",
    "import sys\n",
    "sys.path.append(\"/workspace/zecheng/modelzipper/projects/custom_llama\")\n",
    "from dataclasses import dataclass, field\n",
    "from transformers import Trainer\n",
    "from modelzipper.tutils import *\n",
    "from data.vqllama_dataset import VQDataCollator, VQLLaMAData\n",
    "from models.vqvae import VQVAE\n",
    "from data.svg_data import *\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "VQVAE_CONFIG_PATH = \"/workspace/zecheng/modelzipper/projects/custom_llama/configs/deepspeed/vqvae_config.yaml\"\n",
    "DATA_PATH = \"/zecheng2/svg/icon-shop/test_data_snaps/test_mesh_data_svg_convert_p.pkl\"\n",
    "\n",
    "content = auto_read_data(DATA_PATH)\n",
    "dataset = BasicDataset(dataset=content)\n",
    "vqvae_config = load_yaml_config(VQVAE_CONFIG_PATH)\n",
    "\n",
    "block_kwargs = dict(\n",
    "        width=vqvae_config.vqvae_conv_block.width, \n",
    "        depth=vqvae_config.vqvae_conv_block.depth, \n",
    "        m_conv=vqvae_config.vqvae_conv_block.m_conv,\n",
    "        dilation_growth_rate=vqvae_config.vqvae_conv_block.dilation_growth_rate,\n",
    "        dilation_cycle=vqvae_config.vqvae_conv_block.dilation_cycle,\n",
    "        reverse_decoder_dilation=vqvae_config.vqvae_conv_block.vqvae_reverse_decoder_dilation\n",
    "    )\n",
    "\n",
    "class PluginVQVAE(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "vqvae = VQVAE(vqvae_config, multipliers=None, **block_kwargs)\n",
    "plugin_vqvae = PluginVQVAE(vqvae)\n",
    "checkpoint = torch.load(vqvae_config.ckpt_path)  # load vqvae ckpt\n",
    "plugin_vqvae.load_state_dict(checkpoint['state_dict'])\n",
    "plugin_vqvae.eval()\n",
    "plugin_vqvae.cpu()\n",
    "\n",
    "\n",
    "def cal_compress_padding_mask(x):\n",
    "\n",
    "    # 确保长度是偶数，如果是奇数，可以添加一个值以配合压缩逻辑\n",
    "    if len(x) % 2 != 0:\n",
    "        x = torch.cat((x, torch.tensor([False])))\n",
    "\n",
    "    # 压缩mask\n",
    "    # 使用.view(-1, 2)将原始mask分为两列，然后使用.any(dim=1)检查每对是否有任何True值\n",
    "    x = x.view(-1, 2).any(dim=1)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[0]['svg_path']\n",
    "max_seq_len = 512\n",
    "padded_sample = torch.concatenate([sample, torch.zeros(max_seq_len - sample.shape[0], 9)])\n",
    "padding_mask = ~(padded_sample == 0).all(dim=1, keepdim=True).squeeze()\n",
    "compress_padding_mask = cal_compress_padding_mask(padding_mask)\n",
    "svg_token_ids, _ = plugin_vqvae.model.encode(padded_sample.unsqueeze(0), start_level=0, end_level=1)\n",
    "svg_token_ids = svg_token_ids[0]  # 这里是不加padding mask的svg token ids\n",
    "\n",
    "remain_svg_token_ids = svg_token_ids[:, :compress_padding_mask.sum()] # 这里是加入padding mask的svg token ids\n",
    "\n",
    "postprocess_output = plugin_vqvae.model.decode(svg_token_ids, 0, 1, padding_mask, True, True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_padding_mask = cal_compress_padding_mask(padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_token_ids[:compress_padding_mask.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_token_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
