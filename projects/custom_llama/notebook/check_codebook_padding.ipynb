{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查给codebook引入Padding之后是否会影响模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import transformers\n",
    "import sys\n",
    "sys.path.append(\"/workspace/zecheng/modelzipper/projects/custom_llama\")\n",
    "from dataclasses import dataclass, field\n",
    "from transformers import Trainer\n",
    "from modelzipper.tutils import *\n",
    "from data.vqllama_dataset import VQDataCollator, VQLLaMAData\n",
    "from models.vqvae import VQVAE\n",
    "from data.svg_data import *\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "VQVAE_CONFIG_PATH = \"/workspace/zecheng/modelzipper/projects/custom_llama/configs/deepspeed/vqvae_config.yaml\"\n",
    "DATA_PATH = \"/zecheng2/svg/icon-shop/test_data_snaps/test_mesh_data_svg_convert_p.pkl\"\n",
    "\n",
    "content = auto_read_data(DATA_PATH)\n",
    "dataset = BasicDataset(dataset=content)\n",
    "vqvae_config = load_yaml_config(VQVAE_CONFIG_PATH)\n",
    "\n",
    "block_kwargs = dict(\n",
    "        width=vqvae_config.vqvae_conv_block.width, \n",
    "        depth=vqvae_config.vqvae_conv_block.depth, \n",
    "        m_conv=vqvae_config.vqvae_conv_block.m_conv,\n",
    "        dilation_growth_rate=vqvae_config.vqvae_conv_block.dilation_growth_rate,\n",
    "        dilation_cycle=vqvae_config.vqvae_conv_block.dilation_cycle,\n",
    "        reverse_decoder_dilation=vqvae_config.vqvae_conv_block.vqvae_reverse_decoder_dilation\n",
    "    )\n",
    "\n",
    "class PluginVQVAE(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "vqvae = VQVAE(vqvae_config, multipliers=None, **block_kwargs)\n",
    "plugin_vqvae = PluginVQVAE(vqvae)\n",
    "checkpoint = torch.load(vqvae_config.ckpt_path)  # load vqvae ckpt\n",
    "plugin_vqvae.load_state_dict(checkpoint['state_dict'])\n",
    "plugin_vqvae.eval()\n",
    "plugin_vqvae.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_compress_padding_mask(x):\n",
    "\n",
    "    # 确保长度是偶数，如果是奇数，可以添加一个值以配合压缩逻辑\n",
    "    if len(x) % 2 != 0:\n",
    "        x = torch.cat((x, torch.tensor([False])))\n",
    "\n",
    "    # 压缩mask\n",
    "    # 使用.view(-1, 2)将原始mask分为两列，然后使用.any(dim=1)检查每对是否有任何True值\n",
    "    x = x.view(-1, 2).any(dim=1)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VQVAE' object has no attribute 'normalize_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m(padded_sample \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      5\u001b[0m compress_padding_mask \u001b[38;5;241m=\u001b[39m cal_compress_padding_mask(padding_mask)\n\u001b[0;32m----> 6\u001b[0m svg_token_ids, _ \u001b[38;5;241m=\u001b[39m \u001b[43mplugin_vqvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m svg_token_ids \u001b[38;5;241m=\u001b[39m svg_token_ids[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 这里是不加padding mask的svg token ids\u001b[39;00m\n\u001b[1;32m      9\u001b[0m remain_svg_token_ids \u001b[38;5;241m=\u001b[39m svg_token_ids[:, :compress_padding_mask\u001b[38;5;241m.\u001b[39msum()] \u001b[38;5;66;03m# 这里是加入padding mask的svg token ids\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/zecheng/modelzipper/projects/custom_llama/models/vqvae.py:251\u001b[0m, in \u001b[0;36mVQVAE.encode\u001b[0;34m(self, x, start_level, end_level)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, start_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 251\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_func\u001b[49m(x) \u001b[38;5;66;03m# normalize to [-1, 1]\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     x_in \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# x_in (32, 9, 256)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     xs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/llama/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VQVAE' object has no attribute 'normalize_func'"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]['svg_path']\n",
    "max_seq_len = 512\n",
    "padded_sample = torch.concatenate([sample, torch.zeros(max_seq_len - sample.shape[0], 9)])\n",
    "padding_mask = ~(padded_sample == 0).all(dim=1, keepdim=True).squeeze()\n",
    "compress_padding_mask = cal_compress_padding_mask(padding_mask)\n",
    "svg_token_ids, _ = plugin_vqvae.model.encode(padded_sample.unsqueeze(0), start_level=0, end_level=1)\n",
    "svg_token_ids = svg_token_ids[0]  # 这里是不加padding mask的svg token ids\n",
    "\n",
    "remain_svg_token_ids = svg_token_ids[:, :compress_padding_mask.sum()] # 这里是加入padding mask的svg token ids\n",
    "\n",
    "postprocess_output = plugin_vqvae.model.decode(svg_token_ids, 0, 1, padding_mask, True, True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_padding_mask = cal_compress_padding_mask(padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4769, 6022, 2332, 7758, 1569, 6788, 5531, 7700, 6174, 4948, 7938, 4768,\n",
       "         7525, 4729, 7938, 7561, 3135, 4246, 4114, 8102, 3024, 5743, 5396, 5017,\n",
       "         5853, 1010, 3793, 4587, 7054, 3964, 4413, 3545,  507, 2131, 6577, 3549,\n",
       "         3431, 1318, 7670, 4729, 7149, 4534, 2645, 3456, 7525, 5071, 3070, 1404,\n",
       "         3410, 3949, 5163, 2390, 4154, 6460, 7098, 7818, 2706, 5812, 7903, 5782,\n",
       "          530, 2238,  291, 2219, 3717, 3410, 4328, 5163, 6670, 2634, 3785, 6468,\n",
       "         6595, 2494, 5209]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remain_svg_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4769, 6022, 2332, 7758, 1569, 6788, 5531, 7700, 6174, 4948, 7938, 4768,\n",
       "         7525, 4729, 7938, 7561, 3135, 4246, 4114, 8102, 3024, 5743, 5396, 5017,\n",
       "         5853, 1010, 3793, 4587, 7054, 3964, 4413, 3545,  507, 2131, 6577, 3549,\n",
       "         3431, 1318, 7670, 4729, 7149, 4534, 2645, 3456, 7525, 5071, 3070, 1404,\n",
       "         3410, 3949, 5163, 2390, 4154, 6460, 7098, 7818, 2706, 5812, 7903, 5782,\n",
       "          530, 2238,  291, 2219, 3717, 3410, 4328, 5163, 6670, 2634, 3785, 6468,\n",
       "         6595, 2494, 5209, 5899, 7831, 1287, 6843,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "           68,  437,   95, 2859]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svg_token_ids[:compress_padding_mask.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4769, 6022, 2332, 7758, 1569, 6788, 5531, 7700, 6174, 4948, 7938, 4768,\n",
       "         7525, 4729, 7938, 7561, 3135, 4246, 4114, 8102, 3024, 5743, 5396, 5017,\n",
       "         5853, 1010, 3793, 4587, 7054, 3964, 4413, 3545,  507, 2131, 6577, 3549,\n",
       "         3431, 1318, 7670, 4729, 7149, 4534, 2645, 3456, 7525, 5071, 3070, 1404,\n",
       "         3410, 3949, 5163, 2390, 4154, 6460, 7098, 7818, 2706, 5812, 7903, 5782,\n",
       "          530, 2238,  291, 2219, 3717, 3410, 4328, 5163, 6670, 2634, 3785, 6468,\n",
       "         6595, 2494, 5209, 5899, 7831, 1287, 6843,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "          728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,  728,\n",
       "           68,  437,   95, 2859]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svg_token_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
