exp_task: AR_ywj
state: test
job_id: N4096_D256-N2048_D96
model_name: mamba-1_4b
experiment:
  seed: 27
  results_save_dir: ${exp_task}/${model_name}/version_${job_id}/results
  device_num: 1
  node_num: 1
platform:
  name: langchao_suda
  hf_model_path: /public/home/ljt/hf_models
  dataset_path: /public/home/ljt/tzc/data
  exp_path: /public/home/ljt/tzc/ckpt
  result_path: /public/home/ljt/tzc/data/evaluation
task:
  dataset:
    data_path: ''
    processed_data_path: MQAR/test_C8192_N2048_D96.pkl
    module: custom_dataset.AR_ywj
    class_name: MQARDataset
    nworkers: 4
    max_seq_length: 5000
    train_batch_size: 1
    val_batch_size: 1
    inference_mode: true
    pin_memory: false
    cluster_batch: false
    vocab_size: 8192
    num_examples: 3000
    input_seq_len: 2048
    num_kv_pairs: 96
    test_power_a: 0.01
  other_cfgs:
    max_generation_length: 64
    testing_max_ctx: 5000
model:
  model_name_or_path: mamba-1.4b-hf
  tokenizer_name_or_path: mamba-1.4b-hf
  ckpt_path: /public/home/ljt/tzc/ckpt/AR_ywj-mamba-1_4b/version_MQAR_C8192_N4096_D256/AR_ywj/MQAR_C8192_N4096_D256/checkpoints/last.ckpt
  load_model_state_dict: true
  use_relative_position: false
  use_abs_position: false
  max_position_embeddings: 16384
